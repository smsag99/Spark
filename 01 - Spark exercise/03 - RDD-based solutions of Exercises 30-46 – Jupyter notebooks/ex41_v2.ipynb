{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Ex. 41 v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath  = \"/data/students/bigdata-01QYD/ex_data/Ex41/data/sensors.txt\" # argv[1]\n",
    "outputPath = \"res_out_Ex41v2/\" # argv[2]\n",
    "k = 1 # argv[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the content of the input file\n",
    "readingsRDD = sc.textFile(inputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a filter transformation to select only the lines with PM10>50\n",
    "readingsHighValueRDD = readingsRDD.filter(lambda PM10Reading: float(PM10Reading.split(',')[2])>50 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an RDD of key-value pairs\n",
    "# Each pair contains a sensorId (key) and +1 (value)\n",
    "# It can be implemented by using the map transformation. \n",
    "# The function of the map transformation returns a tuple\n",
    "sensorsPM10CriticalValuesRDD = readingsHighValueRDD.map(lambda PM10Reading: (PM10Reading.split(',')[0], 1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of critical values for each sensor by using the reduceByKey transformation.\n",
    "# The used function is the sum of the values (the sum of the ones)\n",
    "sensorsCountsRDD = sensorsPM10CriticalValuesRDD.reduceByKey(lambda value1, value2: value1+value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort pairs by number of critical values - descending order\n",
    "sortedNumCriticalValuesSensorRDD = sensorsCountsRDD.sortBy(lambda pair: pair[1], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first k elements of sortedNumCriticalValuesSensorRDD.\n",
    "# sortedNumCriticalValuesSensorRDD is sorted. \n",
    "# Hence, the first k elements are the ones we are interested in  \n",
    "topKSensorsNumCriticalValues = sortedNumCriticalValuesSensorRDD.take(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take is an action. Hence, topKCriticalSensors is a local Python variable of the Driver.\n",
    "# Create an RDD of pairs and store it in HDFS by means of the saveAsTextFile method\n",
    "topKSensorsRDD = sc.parallelize(topKSensorsNumCriticalValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topKSensorsRDD.saveAsTextFile(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
